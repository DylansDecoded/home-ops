---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

vars:
  BOOTSTRAP_RESOURCES_DIR: '{{.ROOT_DIR}}/.taskfiles/bootstrap/resources'

tasks:

  kubernetes:
    desc: Bootstrap a Kubernetes cluster [CLUSTER=main] [NODES=m0,m1,...] [ROOK_DISK=/dev/sda]
    prompt: Bootstrap a Kubernetes cluster ... continue?
    vars: &vars
      CLUSTER: '{{.CLUSTER}}'
      NODES: '{{ .NODES | default "k8s-0,k8s-1,k8s-2,k8s-3,k8s-4,k8s-5" }}'
      ROOK_DISK: '{{.ROOK_DISK | default "/dev/sda"}}'
    cmds:
      # - { task: etcd, vars: *vars }
      # - { task: conf, vars: *vars }
      # - { task: apps, vars: *vars }
      # - { task: rook, vars: *vars }
      - { task: flux, vars: *vars }
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl config info &>/dev/null
      - test -f {{.CLUSTER_DIR}}/talosconfig

  etcd:
    internal: true
    cmd: until talosctl --nodes {{.TALOS_CONTROLLER}} bootstrap; do sleep 5; done
    vars:
      TALOS_CONTROLLER:
        sh: talosctl config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1
    preconditions:
      - test -f {{.CLUSTER_DIR}}/talosconfig
      - talosctl config info &>/dev/null

  conf:
    internal: true
    cmd: talosctl kubeconfig --nodes {{.TALOS_CONTROLLER}} --force --force-context-name {{.CLUSTER}} {{.CLUSTER_DIR}}
    vars:
      TALOS_CONTROLLER:
        sh: talosctl config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1
    preconditions:
      - test -f {{.CLUSTER_DIR}}/talosconfig
      - talosctl config info &>/dev/null

  apps:
    internal: true
    cmds:
      - until kubectl wait --for=condition=Ready=False nodes --all --timeout=10m; do sleep 5; done
      - helmfile --file {{.CLUSTER_DIR}}/bootstrap/apps/helmfile.yaml apply --skip-diff-on-install --suppress-diff
      - until kubectl wait --for=condition=Ready nodes --all --timeout=10m; do sleep 5; done
    preconditions:
      - test -f {{.CLUSTER_DIR}}/talosconfig
      - test -f {{.CLUSTER_DIR}}/bootstrap/apps/helmfile.yaml
      - talosctl config info &>/dev/null
  rook:
    internal: true
    cmds:
      # - for: { var: nodes }
      #   task: rook-data
      #   vars:
      #     node: '{{.ITEM}}'

      - for: { var: k8s-0 }
        task: rook-disk
        vars:
          node: k8s-0
          disk: '{{.ITEM}}'

      - for: { var: k8s-1 }
        task: rook-disk
        vars:
          node: k8s-1
          disk: '{{.ITEM}}'

      - for: { var: k8s-2 }
        task: rook-disk
        vars:
          node: k8s-2
          disk: '{{.ITEM}}'

      - for: { var: k8s-3 }
        task: rook-disk
        vars:
         node: k8s-3
         disk: '{{.ITEM}}'

      - for: { var: k8s-4 }
        task: rook-disk
        vars:
         node: k8s-4
         disk: '{{.ITEM}}'

      - for: { var: k8s-5 }
        task: rook-disk
        vars:
          node: k8s-5
          disk: '{{.ITEM}}'

    vars:
      nodes: k8s-2 k8s-3 k8s-4 k8s-5
      k8s-0: sdb
      k8s-1: sda
      k8s-2: sdb
      k8s-3: sda
      k8s-4: sda
      k8s-5: sda
  # rook:
  #   internal: true
  #   vars: &vars
  #     cluster: '{{.cluster}}'
  #     nodes:  k8s-1 k8s-2 k8s-3 k8s-5
  #     disk: '/dev/sdb'
  #   cmds:
  #     - for: { var: nodes }
  #       task: rook-data
  #       vars:
  #         node: '{{.ITEM}}'
  #     - for: { var: nodes }
  #       task: rook-disk
  #       vars:
  #         node: '{{.ITEM}}'
  #         disk: '{{.disk}}'


  rook-data:
    internal: true
    cmds:
      - envsubst < <(cat {{.BOOTSTRAP_RESOURCES_DIR}}/rook-data-job.tmpl.yaml) | kubectl apply -f -
      - bash {{.BOOTSTRAP_RESOURCES_DIR}}/wait-for-job.sh {{.job}} default
      - kubectl --namespace default wait job/{{.job}} --for condition=complete --timeout=1m
      - kubectl --namespace default logs job/{{.job}}
      - kubectl --namespace default delete job {{.job}}
    env:
      job: '{{.job}}'
      node: '{{.node}}'
    vars:
      job: wipe-data-{{.node}}
    preconditions:
      - test -f {{.BOOTSTRAP_RESOURCES_DIR}}/wait-for-job.sh
      - test -f {{.BOOTSTRAP_RESOURCES_DIR}}/rook-data-job.tmpl.yaml

  rook-disk:
    internal: true
    cmds:
      - envsubst < <(cat {{.BOOTSTRAP_RESOURCES_DIR}}/rook-disk-job.tmpl.yaml) | kubectl apply -f -
      - bash {{.BOOTSTRAP_RESOURCES_DIR}}/wait-for-job.sh {{.job}} default
      - kubectl --namespace default wait job/{{.job}} --for condition=complete --timeout=1m
      - kubectl --namespace default logs job/{{.job}}
      - kubectl --namespace default delete job {{.job}}
    env:
      disk: /dev/{{.disk}}
      job: '{{.job}}'
      node: '{{.node}}'
    vars:
      job: wipe-disk-{{.node}}
    preconditions:
      - test -f {{.BOOTSTRAP_RESOURCES_DIR}}/wait-for-job.sh
      - test -f {{.BOOTSTRAP_RESOURCES_DIR}}/rook-disk-job.tmpl.yaml

  flux:
    internal: true
    cmds:
      - kubectl apply --server-side --kustomize {{.CLUSTER_DIR}}/bootstrap/flux
      - sops --decrypt {{.CLUSTER_DIR}}/bootstrap/flux/age-key.secret.sops.yaml | kubectl apply --server-side --filename -
      - sops --decrypt {{.CLUSTER_DIR}}/bootstrap/flux/github-deploy-key.secret.sops.yaml | kubectl apply --server-side --filename -
      - sops --decrypt {{.CLUSTER_DIR}}/flux/vars/cluster-secrets.secret.sops.yaml | kubectl apply --server-side --filename -
      - kubectl apply --server-side --filename {{.CLUSTER_DIR}}/flux/vars/cluster-settings.yaml
      - kubectl apply --server-side --kustomize {{.CLUSTER_DIR}}/flux/config
    preconditions:
      - test -f {{.ROOT_DIR}}/age.key
      - test -f {{.CLUSTER_DIR}}/bootstrap/flux/age-key.secret.sops.yaml
      - test -f {{.CLUSTER_DIR}}/bootstrap/flux/github-deploy-key.secret.sops.yaml
      - test -f {{.CLUSTER_DIR}}/flux/vars/cluster-settings.yaml
      - test -f {{.CLUSTER_DIR}}/flux/vars/cluster-secrets.secret.sops.yaml
      - sops filestatus {{.CLUSTER_DIR}}/bootstrap/flux/age-key.secret.sops.yaml | jq --exit-status '.encrypted'
      - sops filestatus {{.CLUSTER_DIR}}/bootstrap/flux/github-deploy-key.secret.sops.yaml | jq --exit-status '.encrypted'
      - sops filestatus {{.CLUSTER_DIR}}/flux/vars/cluster-secrets.secret.sops.yaml | jq --exit-status '.encrypted'
